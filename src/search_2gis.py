import requests
import pandas as pd
import time
from tqdm import tqdm  

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
API_KEY = "YOUR_API_KEY"  
CITY = "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥"
REGION_ID = 1  
OUTPUT_FILE = "2gis_–ª–æ–¥–æ—á–Ω—ã–µ_–º–∞–≥–∞–∑–∏–Ω—ã.xlsx"

def search_2gis(query, city=CITY, pages=10):
    results = []
    print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}' –≤ –≥–æ—Ä–æ–¥–µ {city}")
    
    for page in tqdm(range(1, pages + 1), desc=f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü ({query})"):
        try:
            url = f"https://catalog.api.2gis.com/3.0/items?q={query}&region_id={REGION_ID}&page={page}&page_size=20&fields=items.point,items.contact_groups&key={API_KEY}"
            response = requests.get(url, headers=HEADERS, timeout=10)
            response.raise_for_status()
            data = response.json()

            for item in data.get("result", {}).get("items", []):
                # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                name = item.get("name", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")
                address = item.get("address_name", "–ù–µ —É–∫–∞–∑–∞–Ω–æ")
                
                # –ö–æ–Ω—Ç–∞–∫—Ç—ã
                phones = []
                emails = []
                websites = []
                
                for group in item.get("contact_groups", []):
                    for contact in group.get("contacts", []):
                        if contact["type"] == "phone":
                            phones.append(contact.get("value", ""))
                        elif contact["type"] == "email":
                            emails.append(contact.get("value", ""))
                        elif contact["type"] == "website":
                            websites.append(contact.get("value", ""))

                results.append({
                    "–ù–∞–∑–≤–∞–Ω–∏–µ": name,
                    "–ê–¥—Ä–µ—Å": address,
                    "–¢–µ–ª–µ—Ñ–æ–Ω": "; ".join(filter(None, phones)),
                    "–°–∞–π—Ç": "; ".join(filter(None, websites)),
                    "–ü–æ—á—Ç–∞": "; ".join(filter(None, emails)),
                    "–ì–æ—Ä–æ–¥": city,
                    "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": query
                })

            time.sleep(0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

        except requests.exceptions.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}): {str(e)}")
            continue
        except Exception as e:
            print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}): {str(e)}")
            continue

    return results

def main():
    queries = [
        "–ª–æ–¥–æ—á–Ω—ã–µ –º–æ—Ç–æ—Ä—ã",
        "–ü–í–• –ª–æ–¥–∫–∏",
        "–∑–∞–ø—á–∞—Å—Ç–∏ –¥–ª—è –ª–æ–¥–æ–∫",
        "–º–∞–≥–∞–∑–∏–Ω –ª–æ–¥–æ–∫",
        "—Å—É–¥–æ–≤—ã–µ –º–∞–≥–∞–∑–∏–Ω—ã"
    ]

    all_results = []
    for query in queries:
        all_results.extend(search_2gis(query, city=CITY, pages=10))

    # –°–æ–∑–¥–∞–µ–º DataFrame –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    df = pd.DataFrame(all_results)
    df.drop_duplicates(subset=["–ù–∞–∑–≤–∞–Ω–∏–µ", "–ê–¥—Ä–µ—Å"], inplace=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
    try:
        with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='–ú–∞–≥–∞–∑–∏–Ω—ã')
        print(f"\n–ì–æ—Ç–æ–≤–æ! –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {OUTPUT_FILE}")
        print(f"–ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Excel: {str(e)}")
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
        csv_file = OUTPUT_FILE.replace('.xlsx', '.csv')
        df.to_csv(csv_file, index=False, encoding='utf-8-sig')
        print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV: {csv_file}")

if __name__ == "__main__":
    main()